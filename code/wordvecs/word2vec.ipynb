{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors with word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this worksheet, make sure to specify VECTORS_DIRECTORY, which is where your (binary-format) Google word vectors are stored. These vectors can be downloaded from https://code.google.com/p/word2vec/. \n",
    "\n",
    "You may also need to ```pip install gensim``` on your machine, if you don't currently have the ```gensim``` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import random\n",
    "VECTORS_DIRECTORY = '/Users/hopkinsm/Projects/thirdparty/word2vec/trunk/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load your word2vec model into memory. Choose either the GoogleNewsModel or the FreebaseModel (both will take a few minutes to load, but the GoogleNewsModel is faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "class GoogleNewsModel:\n",
    "    def __init__(self, vectors_dir):\n",
    "        self.model = KeyedVectors.load_word2vec_format(vectors_dir + \"/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    " \n",
    "    def format_word(self, word):\n",
    "        return '_'.join(word.strip().split())\n",
    "\n",
    "model = GoogleNewsModel(VECTORS_DIRECTORY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define some functions for deadling with word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(model, words, out_file):\n",
    "    out_handle = open(out_file, 'w')\n",
    "    word_not_found_counter = 0\n",
    "    for word in words:\n",
    "        formatted_word = '_'.join(word.strip().split())\n",
    "        if formatted_word in model.model:\n",
    "            out_handle.write(word)\n",
    "            out_handle.write('\\t')   \n",
    "            out_handle.write('\\t'.join([str(num) for num in model.model[formatted_word]]))\n",
    "            out_handle.write('\\n')\n",
    "        else:            \n",
    "            print(\"WARNING: no vector found for \" + unicode(word).encode('utf8'))\n",
    "            word_not_found_counter += 1\n",
    "    out_handle.close()\n",
    "    print(str(word_not_found_counter) + \" out of \" + str(len(words)) + \" words not found.\")\n",
    "\n",
    "def get_word_vector(model, word):\n",
    "    formatted_word = format_word(model, word)\n",
    "    if formatted_word in model.model:\n",
    "        return model.model[formatted_word]\n",
    "    else:\n",
    "        return 'nope'\n",
    "\n",
    "def format_word(model, word):\n",
    "    formatted_word = model.format_word(word)\n",
    "    if formatted_word in model.model:\n",
    "        return formatted_word\n",
    "    elif formatted_word.lower() in model.model:\n",
    "        return formatted_word.lower()\n",
    "    else:\n",
    "        alt_format = ''.join(word.lower().split())\n",
    "        if alt_format in model.model:\n",
    "            return alt_format\n",
    "        else:\n",
    "            return formatted_word\n",
    "        \n",
    "def compute_similarity(model, word1, word2):\n",
    "    return model.model.similarity(format_word(model, word1), format_word(model, word2))\n",
    "   \n",
    "def analogy(A, isto, as_):\n",
    "    result = model.model.most_similar_cosmul(positive=[isto, as_], negative=[A])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out some similarities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6510957\n",
      "0.17920457\n",
      "0.09835236\n",
      "0.46021387\n"
     ]
    }
   ],
   "source": [
    "print(compute_similarity(model, 'king', 'queen'))\n",
    "print(compute_similarity(model, 'king', 'chess'))\n",
    "print(compute_similarity(model, 'king', 'zebra'))\n",
    "print(compute_similarity(model, 'hot', 'cold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out some analogies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aquarium', 0.9578245878219604),\n",
       " ('Aquarium', 0.9497913718223572),\n",
       " ('dolphins', 0.9197266697883606),\n",
       " ('Vancouver_Aquarium', 0.9036914110183716),\n",
       " ('Oceanarium', 0.8904195427894592),\n",
       " ('Zoo', 0.8896881341934204),\n",
       " ('Seaworld', 0.8866909742355347),\n",
       " ('dolphinariums', 0.8841013312339783),\n",
       " ('whale_shark', 0.8743610382080078),\n",
       " ('stillborn_calf', 0.8725596070289612)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('zebra', isto='zoo', as_='dolphin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.9314123392105103),\n",
       " ('monarch', 0.858533501625061),\n",
       " ('princess', 0.8476566076278687),\n",
       " ('Queen_Consort', 0.8150269985198975),\n",
       " ('queens', 0.8099815249443054),\n",
       " ('crown_prince', 0.8089975714683533),\n",
       " ('royal_palace', 0.8027306795120239),\n",
       " ('monarchy', 0.801961362361908),\n",
       " ('prince', 0.800979733467102),\n",
       " ('empress', 0.7958387136459351)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('man', isto='woman', as_='king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beyonce', 0.9388467073440552),\n",
       " ('britney', 0.9098939299583435),\n",
       " ('chris_brown', 0.9000171422958374),\n",
       " ('rihanna', 0.8962053060531616),\n",
       " ('miley', 0.8951844573020935),\n",
       " ('lady_gaga', 0.8941847085952759),\n",
       " ('selena', 0.8923880457878113),\n",
       " ('heidi', 0.8865398168563843),\n",
       " ('miley_cyrus', 0.8859405517578125),\n",
       " ('shes', 0.8803869485855103)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('man', isto='woman', as_='kanye')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guy', 0.9004976153373718),\n",
       " ('boy', 0.8859462141990662),\n",
       " ('Man', 0.8823252320289612),\n",
       " ('teenager', 0.8430608510971069),\n",
       " ('lad', 0.8414479494094849),\n",
       " ('suspected_purse_snatcher', 0.8371303081512451),\n",
       " ('robber', 0.8346849679946899),\n",
       " ('fella', 0.8342578411102295),\n",
       " ('dude', 0.832249104976654),\n",
       " ('chap', 0.8250261545181274)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('woman', isto='man', as_='man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Angelina_Jolie', 0.9859267473220825),\n",
       " ('Jolie', 0.9671158194541931),\n",
       " ('Angeline_Jolie', 0.9343865513801575),\n",
       " ('actress_Angelina_Jolie', 0.9301474094390869),\n",
       " ('Jennifer_Aniston', 0.9110976457595825),\n",
       " ('Julia_Roberts', 0.9050232768058777),\n",
       " ('Nicole_Kidman', 0.8969831466674805),\n",
       " ('Brangelina', 0.8947701454162598),\n",
       " ('hubby_Brad_Pitt', 0.894501805305481),\n",
       " ('Halle_Berry', 0.8915920257568359)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('man', isto='woman', as_='Brad_Pitt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hillary', 0.8977577686309814),\n",
       " ('palin', 0.8898450136184692),\n",
       " ('sarah_palin', 0.8604124188423157),\n",
       " ('oprah', 0.8574645519256592),\n",
       " ('michelle_obama', 0.8549109101295471),\n",
       " ('hillary_clinton', 0.8539676070213318),\n",
       " ('clinton', 0.8533428311347961),\n",
       " ('mccain', 0.8518882989883423),\n",
       " ('barack_obama', 0.8460192680358887),\n",
       " ('miley_cyrus', 0.8413234949111938)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('man', isto='woman', as_='obama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('France', 0.9915590286254883),\n",
       " ('Belgium', 0.8827090859413147),\n",
       " ('Germany', 0.8676550984382629),\n",
       " ('Switzerland', 0.8594647645950317),\n",
       " ('Villebon_Sur_Yvette', 0.8542975783348083),\n",
       " ('extradites_Noriega', 0.8502576947212219),\n",
       " ('Tourcoing', 0.8431874513626099),\n",
       " ('PARIS_AFX_Gaz_de', 0.8378893733024597),\n",
       " ('Dordogne_region', 0.8368163108825684),\n",
       " ('Morocco', 0.8367656469345093)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('Rome', isto=\"Italy\", as_='Paris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Caltech', 0.8554999828338623),\n",
       " ('UC_Santa_Barbara', 0.8236735463142395),\n",
       " ('UCLA', 0.8204423189163208),\n",
       " ('Laboratory_SSRL', 0.8178907036781311),\n",
       " ('IBM_Almaden', 0.8176031112670898),\n",
       " ('SSE_Labs', 0.8147667050361633),\n",
       " ('UCSD', 0.8145511746406555),\n",
       " ('Karl_Deisseroth', 0.8084021806716919),\n",
       " ('Stanford_Synchrotron_Radiation', 0.8060752749443054),\n",
       " ('Zhenan_Bao', 0.8060031533241272)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('Harvard', isto='MIT', as_='Stanford')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chilly', 0.9938065409660339),\n",
       " ('warmth', 0.95757657289505),\n",
       " ('bitterly_cold', 0.9518202543258667),\n",
       " ('colder_temperatures', 0.939226508140564),\n",
       " ('warmer', 0.9386539459228516),\n",
       " ('chill', 0.938201367855072),\n",
       " ('colder', 0.9306686520576477),\n",
       " ('wintry_chill', 0.9274750351905823),\n",
       " ('Warm', 0.9267772436141968),\n",
       " ('chilly_temperatures', 0.9265519976615906)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('hot', isto='cold', as_='warm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('warmer', 1.0093555450439453),\n",
       " ('colder', 0.9644930958747864),\n",
       " ('chillier', 0.9083869457244873),\n",
       " ('drier', 0.902718186378479),\n",
       " ('wetter', 0.895614743232727),\n",
       " ('degrees_warmer', 0.8833713531494141),\n",
       " ('warmest', 0.8638020753860474),\n",
       " ('colder_temperatures', 0.8616779446601868),\n",
       " ('cooler_temperatures', 0.861514687538147),\n",
       " ('warmer_temperatures', 0.8596215844154358)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('hot', isto='hotter', as_='warm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('went', 0.9635381102561951),\n",
       " ('gone', 0.9138423800468445),\n",
       " ('walked', 0.8547773361206055),\n",
       " ('moved', 0.8460192680358887),\n",
       " ('goes', 0.8437943458557129),\n",
       " ('came', 0.8318214416503906),\n",
       " ('stayed', 0.8282606601715088),\n",
       " ('ventured', 0.8271411061286926),\n",
       " ('ran', 0.8173441886901855),\n",
       " ('come', 0.8151555061340332)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('jump', isto='jumped', as_='go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decade', 0.9610583186149597),\n",
       " ('year', 0.95908123254776),\n",
       " ('months', 0.8449519872665405),\n",
       " ('decades', 0.8329842686653137),\n",
       " ('week', 0.8274986147880554),\n",
       " ('years.The', 0.7957645058631897),\n",
       " ('##/#-year', 0.7813944816589355),\n",
       " ('twoyears', 0.7800780534744263),\n",
       " ('since####', 0.7741715908050537),\n",
       " ('recently', 0.7714582085609436)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy('days', isto='month', as_='years')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
